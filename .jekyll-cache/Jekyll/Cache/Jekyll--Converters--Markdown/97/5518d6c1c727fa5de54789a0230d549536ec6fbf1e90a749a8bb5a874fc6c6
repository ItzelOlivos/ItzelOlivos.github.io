I"C<p>Los humanos somos capaces de sobrevivir en un mundo lleno de incertidumbre; por ejemplo, ¬øc√≥mo es que podemos levantarnos a media noche y caminar en penumbras hasta la cocina para beber agua? Para entender c√≥mo es que nuestro cerebro lidia con la incertidumbre durante la ejecuci√≥n de tareas que requieren tomar decisiones de manera secuencial, el Doctor Rajesh Rao, en la Universidad de Washington, propone estudiar c√≥mo es que una red neuronal biol√≥gica podr√≠a implementar los algoritmos con los que un agente artificial (como un robot) resuelve tareas de manera aut√≥noma.</p>

<p>Una manera de resolver problemas de toma de decisi√≥n secuencial (c√≥mo lo es determinar qu√© m√∫sculos mover para desplazarnos de la cama hasta la cocina sin prender la luz) es utilizar modelos matem√°ticos conocidos como ‚Äúprocesos de decisi√≥n Markovianos parcialmente observables (o POMDPs por sus siglas en ingl√©s). Estos modelos construyen distribuciones de probabilidad sobre las variables de inter√©s (ej: si recuerdo haber dejado canicas tiradas en el piso, a mi cerebro le interesa saber exactamente en d√≥nde est√°n para no tropezar con ellas; sin embargo, como no quiero interrumpir mi ritmo circadiano, no debo prender la luz, por lo que la ubicaci√≥n real de las canicas es una variable oculta que debe ser inferida con base en la informaci√≥n que logro recordar). Estas distribuciones de probabilidad, conocidas como ‚Äúbeliefs‚Äú, se actualizan cuando llega nueva informaci√≥n (ej: si al dar un paso, escucho que las canicas se mueven, mi incertidumbre en su posici√≥n disminuir√° considerablemente) y sirven para seleccionar acciones que, con base en toda la informaci√≥n adquirida por los sentidos e inferida por el cerebro, maximizan una funci√≥n de recompensa (ej: llegar a la cocina sin un rasgu√±o).</p>

<p>En el caso de un agente artificial, el proceso para resolver el problema consiste en: 1. adquirir un modelo de c√≥mo evoluciona el ambiente (ej: cu√°les son las leyes f√≠sicas que rigen esa peque√±a parte del universo relacionada directamente con la tarea de inter√©s). 2. Construir beliefs sobre las variables de inter√©s. 3. Actualizar los beliefs conforme el agente interact√∫a con el ambiente y 4. resolver el problema de optimizaci√≥n que determina cu√°l es la secuencia de acciones que maximiza la funci√≥n de recompenza. Sin embargo, en el caso de una red neuronal biol√≥gica, todos los puntos antes descritos deben ser implementados utilizando √∫nicamente trenes de impulsos el√©ctricos (conocidos como spikes); estos spikes son el mecanismo mediante el cual las neuronas se comunican casi instant√°neamente unas con otras y constituyen una de las principales diferencias en cuanto al procesamiento de informaci√≥n en cerebros y computadoras.</p>

<p>El Doctor Rao en su art√≠culo de investigaci√≥n ‚Äú<a href="https://www.frontiersin.org/articles/10.3389/fncom.2010.00146/full">Decision-making under uncertainty: a neural model based on partially observable Markov decision process</a>‚Äú, publicado en la revista Frontiers in Computational Neuroscience, explica 3 razones por las que es plausible que el cerebro utilice un mecanismo similar al algoritmo que hoy en d√≠a utilizan muchos agentes artificiales, Point-based POMDP:</p>

<p>El ruido intr√≠nseco de la actividad neuronal en el cerebro puede codificar distribuciones de probabilidad.</p>

<p>Un circuito de neuronas comunic√°ndose de forma recurrente es capaz de implementar inferencia Bayesiana (que es lo que nos permite sacar conclusiones a partir de informaci√≥n parcial).</p>

<p>Estudios de fisiolog√≠a demuestran que la ganglia basal implementa estrategias similares a las de agentes basados en reinforcement learning para identificar secuencias de acciones que maximizan la funci√≥n de recompensa.</p>

<p>Hay un largo camino que recorrer antes de descifrar todos los misterios detr√°s de los mecanismos mediante los cuales el cerebro es capaz de medir, manipular y reducir su incertidumbre para decidir c√≥mo comportarse racionalmente; sin embargo, esta l√≠nea de investigaci√≥n ofrece resultados interesantes que bien vale la pena seguir explorando üôÇ</p>
:ET