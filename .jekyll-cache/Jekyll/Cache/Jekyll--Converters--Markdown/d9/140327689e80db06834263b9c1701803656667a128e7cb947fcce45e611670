I"-<p>Transmitir en vivo est√° de moda y ¬°qu√© mejor que hacerlo en 4K!; sin embargo, el ancho de banda disponible en dispositivos m√≥viles puede convertirse en un obst√°culo dif√≠cil de superar. Para resolver este problema, investigadores del Korea Advanced Institute of Science and Technology proponen una nueva arquitectura cliente-servidor llamada liveNAS. La idea es permitir al cliente (nosotros) transmitir video con la calidad que permite su ancho de banda y pedirle a un servidor (Amazon web services, por ejemplo) que escale los cuadros de video usando una red neuronal que continuamente aprende a mapear im√°genes de baja a alta resoluci√≥n.</p>

<p>El principal reto detr√°s de esta idea es implementar un algoritmo capaz de aprender de manera continua y adaptarse a los cambios (casi siempre inesperados) del mundo real, esta es la raz√≥n por la que la rob√≥tica, por ejemplo, es una de las √∫ltimas fronteras en el aprendizaje autom√°tico. As√≠ pues, la propuesta de LiveNAS para entrenar una red neuronal artificial en tiempo (casi) real es explotar la redundancia en las im√°genes que nos rodean (te explico esto m√°s adelante) y el poder del c√≥mputo en paralelo.</p>

<p>El primer componente de esta arquitectura es el ‚ÄúPatch sampler‚Äù. La tarea de este componente es determinar qu√© fragmentos de los fotogramas que se desean transmitir ser√°n dif√≠ciles de escalar a alta resoluci√≥n. Para lograr esto: 1) Se comprime el fotograma original, se descomprime y se mide qu√© tanto se distorsiono despu√©s de este proceso, 2) El fotograma original se divide en muchos pedacitos (parches), se selecciona uno al azar, se comprime, se descomprime y se mide nuevamente qu√© tanto se distorsion√≥, 3) Si se detecta que el parche se distorsion√≥ mucho m√°s que el fotograma completo, √©ste se etiqueta como una ‚Äúmuestra interesante‚Äù, 4) Los pasos 2 y 3 se repiten hasta juntar 10 muestras interesantes y se env√≠an al servidor. Del lado del servidor, el componente ‚ÄúContent-adaptive trainer‚Äù consume las muestras interesantes y ajusta los par√°metros de una red neuronal artificial cuyo objetivo es aprender a escalar im√°genes de baja a alta resoluci√≥n.</p>

<p>Enviar solo 10 parchecitos para alimentar a la red neuronal en lugar del fotograma completo reduce considerablemente el tiempo de entrenamiento. Esta idea funciona porque el mundo que nos rodea es ¬°s√∫per redundante! Como podemos ver en la siguiente secuencia de fotogramas, pixeles de colores similares aparecen juntos en grandes √°reas dentro del fotograma y permanecen juntos en fotogramas subsecuentes; esta redundancia hace que las partes m√°s informativas de las im√°genes del mundo que nos rodea sean los bordes (no por nada nuestros ojitos evolucionaron para detectar bordes, aprende m√°s <a href="https://www.sciencedirect.com/science/article/pii/S0042698997001211">aqu√≠</a>).</p>

<p>Finalmente, la arquitectura consider un ‚ÄúSuper-resolution processor‚Äù del lado del servidor; este componente cuenta con GPUs para procesar varios fotogramas simult√°neamente. El resultado final es un escalamiento autom√°tico de im√°genes tan veloz que da la impresi√≥n al usuario final (followers de Tik Tok, por ejemplo) de estar consumiendo de video en 4K a pesar de las fallas de origen.</p>

<p>Si quieres leer el art√≠culo completo, √©ste fue publicado en Julio 2020 para the Annual conference of the ACM Special Interest Group on Data Communication on the applications, technologies, architectures, and protocols for computer communication (SIGCOMM ‚Äô20). Encu√©ntralo <a href="https://dl.acm.org/doi/10.1145/3387514.3405856">aqu√≠</a>!</p>
:ET